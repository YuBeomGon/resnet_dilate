{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sealed-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import cv2\n",
    "import os\n",
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from resnet_auen_hidden import *\n",
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "drawn-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict \n",
    "args = easydict.EasyDict({ \"batch-size\": 256, \n",
    "                          \"epochs\": 20, \n",
    "                          \"data\": 0, \n",
    "                          'arch':'resnet18',\n",
    "                          'lr':0.1,\n",
    "                         'momentum':0.9,\n",
    "                         'weight_decay':1e-4,\n",
    "                         'start_epoch':0,\n",
    "                         'gpu':0,\n",
    "                          'print_freq':1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "destroyed-airline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear layer is initialized\n",
      "linear layer is initialized\n",
      "linear layer is initialized\n",
      "tensor([ 0.0110, -0.0367, -0.0128, -0.0016, -0.0285, -0.0435, -0.0510],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([-0.0104, -0.0061, -0.0018,  0.0748,  0.0566,  0.0171, -0.0127],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "backbone_model= torchvision.models.resnet18(pretrained=True)\n",
    "model = resnet18(pretrained=False)\n",
    "nn.init.constant_(model.auen.bn1.weight, 0)\n",
    "nn.init.constant_(model.auen.bn2.weight, 0)\n",
    "print(model.conv1.weight[0,0,0])\n",
    "model.load_state_dict(backbone_model.state_dict(), strict=False)\n",
    "print(model.conv1.weight[0,0,0])\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "#                             momentum=args.momentum,\n",
    "#                             weight_decay=args.weight_decay)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coral-freedom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.auen.bn1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "committed-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading code\n",
    "data_dir = '../ILSVRC/Data/CLS-LOC/'\n",
    "traindir = os.path.join(data_dir, 'train')\n",
    "valdir = os.path.join(data_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "coated-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "val_dataset = datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "superb-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = None\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=256, shuffle=(train_sampler is None),\n",
    "    num_workers=8, pin_memory=True, sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "square-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32, shuffle=False,\n",
    "    num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "blind-constitution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (auen): AutoEncoder(\n",
       "    (fc1): Linear(in_features=512, out_features=32, bias=True)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc2): Linear(in_features=32, out_features=512, bias=True)\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (gelu): GELU()\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (gelu): GELU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (gelu): GELU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (gelu): GELU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (gelu): GELU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (gelu): GELU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (gelu): GELU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (gelu): GELU()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (gelu): GELU()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  (loss): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-polyester",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/5005]\tTime  2.909 ( 2.909)\tData  2.300 ( 2.300)\tLoss 3.2712e+00 (3.2712e+00)\tAcc@1  39.45 ( 39.45)\tAcc@5  58.20 ( 58.20)\n",
      "Epoch: [0][1000/5005]\tTime  0.330 ( 0.340)\tData  0.000 ( 0.003)\tLoss 2.0268e+00 (2.0182e+00)\tAcc@1  53.12 ( 54.52)\tAcc@5  74.61 ( 77.32)\n",
      "Epoch: [0][2000/5005]\tTime  0.357 ( 0.341)\tData  0.000 ( 0.001)\tLoss 2.1739e+00 (1.9829e+00)\tAcc@1  52.73 ( 55.13)\tAcc@5  75.78 ( 77.87)\n",
      "Epoch: [0][3000/5005]\tTime  0.342 ( 0.342)\tData  0.000 ( 0.001)\tLoss 2.1030e+00 (1.9606e+00)\tAcc@1  55.86 ( 55.51)\tAcc@5  77.34 ( 78.22)\n",
      "Epoch: [0][4000/5005]\tTime  0.356 ( 0.343)\tData  0.000 ( 0.001)\tLoss 1.8116e+00 (1.9474e+00)\tAcc@1  59.38 ( 55.77)\tAcc@5  81.25 ( 78.44)\n",
      "Epoch: [0][5000/5005]\tTime  0.326 ( 0.340)\tData  0.000 ( 0.001)\tLoss 1.9038e+00 (1.9351e+00)\tAcc@1  53.91 ( 56.01)\tAcc@5  78.52 ( 78.64)\n",
      "Test: [   0/1565]\tTime  0.347 ( 0.347)\tLoss 8.6259e-01 (8.6259e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  93.75 ( 93.75)\n",
      "Test: [1000/1565]\tTime  0.015 ( 0.050)\tLoss 2.2628e+00 (1.4806e+00)\tAcc@1  21.88 ( 63.70)\tAcc@5  84.38 ( 86.15)\n",
      " * Acc@1 61.187 Acc@5 84.071\n",
      "************train_loss 1.9350736419989805 val_acc 61.187355041503906*************\n",
      "epoch time 1778.5453081130981\n",
      "Epoch: [1][   0/5005]\tTime  2.226 ( 2.226)\tData  2.088 ( 2.088)\tLoss 1.6095e+00 (1.6095e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  84.77 ( 84.77)\n",
      "Epoch: [1][1000/5005]\tTime  0.338 ( 0.347)\tData  0.000 ( 0.003)\tLoss 2.0035e+00 (1.8269e+00)\tAcc@1  49.61 ( 58.08)\tAcc@5  77.34 ( 80.25)\n",
      "Epoch: [1][2000/5005]\tTime  0.344 ( 0.346)\tData  0.000 ( 0.002)\tLoss 1.6981e+00 (1.8246e+00)\tAcc@1  58.20 ( 58.15)\tAcc@5  81.64 ( 80.27)\n",
      "Epoch: [1][3000/5005]\tTime  0.342 ( 0.345)\tData  0.000 ( 0.001)\tLoss 1.6619e+00 (1.8216e+00)\tAcc@1  58.59 ( 58.19)\tAcc@5  85.16 ( 80.30)\n",
      "Epoch: [1][4000/5005]\tTime  0.328 ( 0.344)\tData  0.000 ( 0.001)\tLoss 1.6577e+00 (1.8179e+00)\tAcc@1  61.72 ( 58.27)\tAcc@5  83.20 ( 80.35)\n",
      "Epoch: [1][5000/5005]\tTime  0.326 ( 0.340)\tData  0.000 ( 0.001)\tLoss 1.7783e+00 (1.8123e+00)\tAcc@1  56.25 ( 58.40)\tAcc@5  83.59 ( 80.43)\n",
      "Test: [   0/1565]\tTime  0.352 ( 0.352)\tLoss 1.0007e+00 (1.0007e+00)\tAcc@1  81.25 ( 81.25)\tAcc@5  90.62 ( 90.62)\n",
      "Test: [1000/1565]\tTime  0.017 ( 0.048)\tLoss 2.0425e+00 (1.4149e+00)\tAcc@1  43.75 ( 65.03)\tAcc@5  81.25 ( 87.08)\n",
      " * Acc@1 62.604 Acc@5 84.884\n",
      "************train_loss 1.812231292046234 val_acc 62.6036262512207*************\n",
      "epoch time 1778.0985641479492\n",
      "Epoch: [2][   0/5005]\tTime  2.629 ( 2.629)\tData  2.506 ( 2.506)\tLoss 1.7070e+00 (1.7070e+00)\tAcc@1  61.72 ( 61.72)\tAcc@5  80.86 ( 80.86)\n",
      "Epoch: [2][1000/5005]\tTime  0.374 ( 0.332)\tData  0.000 ( 0.003)\tLoss 1.5960e+00 (1.7436e+00)\tAcc@1  60.55 ( 59.72)\tAcc@5  85.94 ( 81.34)\n",
      "Epoch: [2][2000/5005]\tTime  0.332 ( 0.339)\tData  0.000 ( 0.002)\tLoss 1.4583e+00 (1.7445e+00)\tAcc@1  63.28 ( 59.78)\tAcc@5  84.77 ( 81.35)\n",
      "Epoch: [2][3000/5005]\tTime  0.338 ( 0.341)\tData  0.000 ( 0.001)\tLoss 1.7555e+00 (1.7422e+00)\tAcc@1  60.16 ( 59.84)\tAcc@5  81.25 ( 81.41)\n",
      "Epoch: [2][4000/5005]\tTime  0.343 ( 0.341)\tData  0.000 ( 0.001)\tLoss 2.1039e+00 (1.7403e+00)\tAcc@1  52.73 ( 59.87)\tAcc@5  76.56 ( 81.42)\n",
      "Epoch: [2][5000/5005]\tTime  0.351 ( 0.342)\tData  0.000 ( 0.001)\tLoss 1.8470e+00 (1.7402e+00)\tAcc@1  54.69 ( 59.84)\tAcc@5  79.30 ( 81.41)\n",
      "Test: [   0/1565]\tTime  0.373 ( 0.373)\tLoss 6.2034e-01 (6.2034e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [1000/1565]\tTime  0.018 ( 0.049)\tLoss 2.7973e+00 (1.3793e+00)\tAcc@1  12.50 ( 66.11)\tAcc@5  75.00 ( 87.32)\n",
      " * Acc@1 63.521 Acc@5 85.388\n",
      "************train_loss 1.7401074319453664 val_acc 63.5205078125*************\n",
      "epoch time 1787.941208600998\n",
      "Epoch: [3][   0/5005]\tTime  2.477 ( 2.477)\tData  2.351 ( 2.351)\tLoss 1.7842e+00 (1.7842e+00)\tAcc@1  58.98 ( 58.98)\tAcc@5  82.42 ( 82.42)\n",
      "Epoch: [3][1000/5005]\tTime  0.359 ( 0.345)\tData  0.000 ( 0.003)\tLoss 1.7035e+00 (1.6708e+00)\tAcc@1  60.55 ( 61.25)\tAcc@5  80.08 ( 82.34)\n",
      "Epoch: [3][2000/5005]\tTime  0.358 ( 0.340)\tData  0.000 ( 0.002)\tLoss 1.6571e+00 (1.6801e+00)\tAcc@1  62.50 ( 61.04)\tAcc@5  82.42 ( 82.21)\n",
      "Epoch: [3][3000/5005]\tTime  0.323 ( 0.336)\tData  0.000 ( 0.001)\tLoss 1.7102e+00 (1.6828e+00)\tAcc@1  58.59 ( 60.96)\tAcc@5  81.64 ( 82.20)\n",
      "Epoch: [3][4000/5005]\tTime  0.327 ( 0.334)\tData  0.000 ( 0.001)\tLoss 1.9044e+00 (1.6834e+00)\tAcc@1  55.47 ( 60.95)\tAcc@5  80.86 ( 82.20)\n",
      "Epoch: [3][5000/5005]\tTime  0.323 ( 0.333)\tData  0.000 ( 0.001)\tLoss 1.8281e+00 (1.6837e+00)\tAcc@1  56.25 ( 60.94)\tAcc@5  79.69 ( 82.20)\n",
      "Test: [   0/1565]\tTime  0.355 ( 0.355)\tLoss 8.9683e-01 (8.9683e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  90.62 ( 90.62)\n",
      "Test: [1000/1565]\tTime  0.015 ( 0.048)\tLoss 1.9066e+00 (1.3599e+00)\tAcc@1  34.38 ( 66.41)\tAcc@5  84.38 ( 87.77)\n",
      " * Acc@1 64.361 Acc@5 85.983\n",
      "************train_loss 1.683725069643708 val_acc 64.36148071289062*************\n",
      "epoch time 1740.588790178299\n",
      "Epoch: [4][   0/5005]\tTime  2.368 ( 2.368)\tData  2.232 ( 2.232)\tLoss 1.6706e+00 (1.6706e+00)\tAcc@1  60.55 ( 60.55)\tAcc@5  80.86 ( 80.86)\n",
      "Epoch: [4][1000/5005]\tTime  0.364 ( 0.332)\tData  0.000 ( 0.003)\tLoss 1.3337e+00 (1.6273e+00)\tAcc@1  67.97 ( 62.11)\tAcc@5  87.11 ( 83.03)\n",
      "Epoch: [4][2000/5005]\tTime  0.342 ( 0.341)\tData  0.000 ( 0.002)\tLoss 1.4320e+00 (1.6337e+00)\tAcc@1  67.58 ( 61.99)\tAcc@5  85.55 ( 82.94)\n",
      "Epoch: [4][3000/5005]\tTime  0.360 ( 0.343)\tData  0.000 ( 0.001)\tLoss 1.6364e+00 (1.6395e+00)\tAcc@1  60.55 ( 61.86)\tAcc@5  84.38 ( 82.86)\n",
      "Epoch: [4][4000/5005]\tTime  0.335 ( 0.344)\tData  0.000 ( 0.001)\tLoss 1.4892e+00 (1.6424e+00)\tAcc@1  64.06 ( 61.80)\tAcc@5  85.94 ( 82.82)\n",
      "Epoch: [4][5000/5005]\tTime  0.360 ( 0.345)\tData  0.000 ( 0.001)\tLoss 1.6869e+00 (1.6433e+00)\tAcc@1  59.38 ( 61.77)\tAcc@5  81.64 ( 82.82)\n",
      "Test: [   0/1565]\tTime  0.371 ( 0.371)\tLoss 8.2551e-01 (8.2551e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5  93.75 ( 93.75)\n",
      "Test: [1000/1565]\tTime  0.016 ( 0.052)\tLoss 2.7194e+00 (1.3364e+00)\tAcc@1   6.25 ( 67.32)\tAcc@5  78.12 ( 88.13)\n",
      " * Acc@1 65.141 Acc@5 86.271\n",
      "************train_loss 1.643321721515413 val_acc 65.14053344726562*************\n",
      "epoch time 1809.3468294143677\n",
      "Epoch: [5][   0/5005]\tTime  2.401 ( 2.401)\tData  2.246 ( 2.246)\tLoss 1.5114e+00 (1.5114e+00)\tAcc@1  65.23 ( 65.23)\tAcc@5  85.55 ( 85.55)\n",
      "Epoch: [5][1000/5005]\tTime  0.351 ( 0.355)\tData  0.000 ( 0.003)\tLoss 1.4917e+00 (1.5907e+00)\tAcc@1  63.67 ( 62.80)\tAcc@5  87.50 ( 83.48)\n",
      "Epoch: [5][2000/5005]\tTime  0.362 ( 0.354)\tData  0.000 ( 0.002)\tLoss 1.4857e+00 (1.6001e+00)\tAcc@1  65.23 ( 62.64)\tAcc@5  84.77 ( 83.37)\n",
      "Epoch: [5][3000/5005]\tTime  0.360 ( 0.354)\tData  0.000 ( 0.001)\tLoss 1.5719e+00 (1.6017e+00)\tAcc@1  63.28 ( 62.60)\tAcc@5  80.86 ( 83.35)\n",
      "Epoch: [5][4000/5005]\tTime  0.365 ( 0.353)\tData  0.000 ( 0.001)\tLoss 1.5126e+00 (1.6057e+00)\tAcc@1  64.45 ( 62.55)\tAcc@5  85.94 ( 83.29)\n",
      "Epoch: [5][5000/5005]\tTime  0.337 ( 0.353)\tData  0.000 ( 0.001)\tLoss 1.7149e+00 (1.6078e+00)\tAcc@1  60.55 ( 62.52)\tAcc@5  81.64 ( 83.26)\n",
      "Test: [   0/1565]\tTime  0.361 ( 0.361)\tLoss 8.1355e-01 (8.1355e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5  93.75 ( 93.75)\n",
      "Test: [1000/1565]\tTime  0.014 ( 0.050)\tLoss 2.2950e+00 (1.3052e+00)\tAcc@1  25.00 ( 67.86)\tAcc@5  81.25 ( 88.54)\n",
      " * Acc@1 65.552 Acc@5 86.864\n",
      "************train_loss 1.6077186665693566 val_acc 65.55203247070312*************\n",
      "epoch time 1846.3238463401794\n",
      "Epoch: [6][   0/5005]\tTime  2.582 ( 2.582)\tData  2.456 ( 2.456)\tLoss 1.2882e+00 (1.2882e+00)\tAcc@1  66.41 ( 66.41)\tAcc@5  89.06 ( 89.06)\n",
      "Epoch: [6][1000/5005]\tTime  0.338 ( 0.330)\tData  0.000 ( 0.003)\tLoss 1.7559e+00 (1.5596e+00)\tAcc@1  60.16 ( 63.45)\tAcc@5  81.64 ( 83.93)\n",
      "Epoch: [6][2000/5005]\tTime  0.343 ( 0.330)\tData  0.000 ( 0.002)\tLoss 1.6927e+00 (1.5692e+00)\tAcc@1  59.77 ( 63.35)\tAcc@5  82.03 ( 83.79)\n",
      "Epoch: [6][3000/5005]\tTime  0.337 ( 0.329)\tData  0.000 ( 0.001)\tLoss 1.5791e+00 (1.5724e+00)\tAcc@1  66.41 ( 63.24)\tAcc@5  82.03 ( 83.73)\n",
      "Epoch: [6][4000/5005]\tTime  0.327 ( 0.329)\tData  0.000 ( 0.001)\tLoss 1.8507e+00 (1.5752e+00)\tAcc@1  60.16 ( 63.18)\tAcc@5  78.52 ( 83.71)\n",
      "Epoch: [6][5000/5005]\tTime  0.317 ( 0.329)\tData  0.000 ( 0.001)\tLoss 1.4661e+00 (1.5773e+00)\tAcc@1  66.80 ( 63.12)\tAcc@5  83.20 ( 83.69)\n",
      "Test: [   0/1565]\tTime  0.353 ( 0.353)\tLoss 8.3176e-01 (8.3176e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5  90.62 ( 90.62)\n",
      "Test: [1000/1565]\tTime  0.018 ( 0.048)\tLoss 1.8229e+00 (1.2910e+00)\tAcc@1  53.12 ( 67.93)\tAcc@5  81.25 ( 88.76)\n",
      " * Acc@1 65.804 Acc@5 86.924\n",
      "************train_loss 1.5771976440766775 val_acc 65.80371856689453*************\n",
      "epoch time 1721.341727256775\n",
      "Epoch: [7][   0/5005]\tTime  2.466 ( 2.466)\tData  2.335 ( 2.335)\tLoss 1.5898e+00 (1.5898e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  84.38 ( 84.38)\n",
      "Epoch: [7][1000/5005]\tTime  0.328 ( 0.329)\tData  0.000 ( 0.003)\tLoss 1.4053e+00 (1.5328e+00)\tAcc@1  65.62 ( 63.95)\tAcc@5  85.16 ( 84.33)\n",
      "Epoch: [7][2000/5005]\tTime  0.325 ( 0.329)\tData  0.000 ( 0.002)\tLoss 1.6597e+00 (1.5430e+00)\tAcc@1  59.77 ( 63.79)\tAcc@5  83.98 ( 84.16)\n",
      "Epoch: [7][3000/5005]\tTime  0.326 ( 0.329)\tData  0.000 ( 0.001)\tLoss 1.5260e+00 (1.5465e+00)\tAcc@1  65.62 ( 63.71)\tAcc@5  83.98 ( 84.12)\n",
      "Epoch: [7][4000/5005]\tTime  0.320 ( 0.329)\tData  0.000 ( 0.001)\tLoss 1.8788e+00 (1.5501e+00)\tAcc@1  57.42 ( 63.66)\tAcc@5  79.69 ( 84.07)\n",
      "Epoch: [7][5000/5005]\tTime  0.327 ( 0.329)\tData  0.000 ( 0.001)\tLoss 1.5785e+00 (1.5524e+00)\tAcc@1  62.89 ( 63.62)\tAcc@5  84.38 ( 84.03)\n",
      "Test: [   0/1565]\tTime  0.348 ( 0.348)\tLoss 9.6266e-01 (9.6266e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5  87.50 ( 87.50)\n",
      "Test: [1000/1565]\tTime  0.014 ( 0.048)\tLoss 2.2588e+00 (1.2738e+00)\tAcc@1  28.12 ( 68.44)\tAcc@5  81.25 ( 88.98)\n",
      " * Acc@1 66.203 Acc@5 87.126\n",
      "************train_loss 1.5525086061709747 val_acc 66.20323181152344*************\n",
      "epoch time 1720.8227882385254\n",
      "Epoch: [8][   0/5005]\tTime  2.091 ( 2.091)\tData  1.960 ( 1.960)\tLoss 1.7497e+00 (1.7497e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  81.64 ( 81.64)\n",
      "Epoch: [8][1000/5005]\tTime  0.337 ( 0.330)\tData  0.000 ( 0.002)\tLoss 1.5650e+00 (1.5099e+00)\tAcc@1  64.45 ( 64.41)\tAcc@5  83.20 ( 84.59)\n",
      "Epoch: [8][2000/5005]\tTime  0.318 ( 0.329)\tData  0.000 ( 0.001)\tLoss 1.6824e+00 (1.5157e+00)\tAcc@1  61.33 ( 64.35)\tAcc@5  84.77 ( 84.51)\n"
     ]
    }
   ],
   "source": [
    "best_acc1 = 0\n",
    "acc1 = 0\n",
    "train_loss = []\n",
    "val_acc = []\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    start_time = time.time()\n",
    "#     adjust_learning_rate(optimizer, epoch, args)\n",
    "\n",
    "    # train for one epoch\n",
    "    epoch_loss = train(train_loader, model, criterion, optimizer, epoch, args)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion, args)  \n",
    "    \n",
    "    train_loss.append(epoch_loss)\n",
    "    val_acc.append(acc1)\n",
    "    print('************train_loss {} val_acc {}*************'.format(epoch_loss, acc1))\n",
    "    \n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "#     if not args.multiprocessing_distributed or (args.multiprocessing_distributed\n",
    "#             and args.rank % ngpus_per_node == 0):\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': args.arch,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    print('epoch time', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-battery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-hunter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-junior",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-handy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_retina",
   "language": "python",
   "name": "pytorch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
