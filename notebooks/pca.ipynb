{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rising-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import cv2\n",
    "import os\n",
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from resnet import *\n",
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "standard-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict \n",
    "args = easydict.EasyDict({ \"batch-size\": 256, \n",
    "                          \"epochs\": 80, \n",
    "                          \"data\": 0, \n",
    "                          'arch':'resnet18',\n",
    "                          'lr':0.1,\n",
    "                         'momentum':0.9,\n",
    "                         'weight_decay':1e-4,\n",
    "                         'start_epoch':0,\n",
    "                         'gpu':0,\n",
    "                          'print_freq':3000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "superior-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = resnet18(pretrained=False)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "worth-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading code\n",
    "data_dir = '../ILSVRC/Data/CLS-LOC/'\n",
    "traindir = os.path.join(data_dir, 'train')\n",
    "valdir = os.path.join(data_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "focal-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "val_dataset = datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "meaning-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = None\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=256, shuffle=(train_sampler is None),\n",
    "    num_workers=8, pin_memory=True, sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tight-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32, shuffle=False,\n",
    "    num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unavailable-crack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (gelu): GELU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (gelu): GELU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (gelu): GELU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (gelu): GELU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (gelu): GELU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (gelu): GELU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (gelu): GELU()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (gelu): GELU()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nutritional-electronics",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/5005]\tTime  2.832 ( 2.832)\tData  2.411 ( 2.411)\tLoss 7.0142e+00 (7.0142e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.39 (  0.39)\n",
      "Epoch: [0][3000/5005]\tTime  0.314 ( 0.634)\tData  0.000 ( 0.001)\tLoss 4.5555e+00 (5.3605e+00)\tAcc@1  15.23 (  7.19)\tAcc@5  34.77 ( 18.86)\n",
      "Test: [   0/1565]\tTime  0.344 ( 0.344)\tLoss 2.6602e+00 (2.6602e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5  65.62 ( 65.62)\n",
      " * Acc@1 16.006 Acc@5 37.328\n",
      "************train_loss None val_acc 16.006473541259766*************\n",
      "Parameter containing:\n",
      "tensor([[ 2.6945, -0.4133, -1.9093],\n",
      "        [ 1.2610,  3.7624, -2.9204],\n",
      "        [ 1.4330,  0.1944,  0.5236]], device='cuda:0', requires_grad=True)\n",
      "epoch time 3213.737607240677\n",
      "Epoch: [1][   0/5005]\tTime  2.745 ( 2.745)\tData  2.294 ( 2.294)\tLoss 3.7242e+00 (3.7242e+00)\tAcc@1  23.83 ( 23.83)\tAcc@5  48.05 ( 48.05)\n",
      "Epoch: [1][3000/5005]\tTime  0.312 ( 0.621)\tData  0.000 ( 0.001)\tLoss 3.0290e+00 (3.5681e+00)\tAcc@1  35.94 ( 26.98)\tAcc@5  62.89 ( 50.97)\n",
      "Test: [   0/1565]\tTime  0.349 ( 0.349)\tLoss 2.3645e+00 (2.3645e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5  78.12 ( 78.12)\n",
      " * Acc@1 23.911 Acc@5 48.261\n",
      "************train_loss None val_acc 23.910829544067383*************\n",
      "Parameter containing:\n",
      "tensor([[ 2.2703, -0.5563, -2.2846],\n",
      "        [ 2.0761,  4.0240, -3.1361],\n",
      "        [ 1.4401, -0.5113,  0.1726]], device='cuda:0', requires_grad=True)\n",
      "epoch time 3211.942657470703\n",
      "Epoch: [2][   0/5005]\tTime  2.420 ( 2.420)\tData  2.299 ( 2.299)\tLoss 3.0530e+00 (3.0530e+00)\tAcc@1  35.94 ( 35.94)\tAcc@5  58.98 ( 58.98)\n",
      "Epoch: [2][3000/5005]\tTime  0.308 ( 0.644)\tData  0.000 ( 0.001)\tLoss 3.0772e+00 (3.0644e+00)\tAcc@1  33.98 ( 35.09)\tAcc@5  57.42 ( 60.22)\n",
      "Test: [   0/1565]\tTime  0.352 ( 0.352)\tLoss 2.3462e+00 (2.3462e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  78.12 ( 78.12)\n",
      " * Acc@1 29.134 Acc@5 54.985\n",
      "************train_loss None val_acc 29.134456634521484*************\n",
      "Parameter containing:\n",
      "tensor([[ 1.6499, -0.9221, -2.8636],\n",
      "        [ 3.1294,  4.2280, -2.1148],\n",
      "        [ 0.7918, -0.1085,  0.2302]], device='cuda:0', requires_grad=True)\n",
      "epoch time 3289.724231004715\n",
      "Epoch: [3][   0/5005]\tTime  2.274 ( 2.274)\tData  2.152 ( 2.152)\tLoss 2.9273e+00 (2.9273e+00)\tAcc@1  38.28 ( 38.28)\tAcc@5  62.89 ( 62.89)\n",
      "Epoch: [3][3000/5005]\tTime  0.705 ( 0.629)\tData  0.000 ( 0.001)\tLoss 2.9529e+00 (2.8414e+00)\tAcc@1  36.72 ( 38.94)\tAcc@5  60.94 ( 64.22)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e1f43ecdd508>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch/imagenet/main.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, args)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;31m# measure accuracy and record loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0macc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mtop1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mtop5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_acc1 = 0\n",
    "acc1 = 0\n",
    "train_loss = []\n",
    "val_acc = []\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    start_time = time.time()\n",
    "    adjust_learning_rate(optimizer, epoch, args)\n",
    "\n",
    "    # train for one epoch\n",
    "    epoch_loss = train(train_loader, model, criterion, optimizer, epoch, args)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion, args)  \n",
    "    \n",
    "    train_loss.append(epoch_loss)\n",
    "    val_acc.append(acc1)\n",
    "    print('************train_loss {} val_acc {}*************'.format(epoch_loss, acc1))\n",
    "    \n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "#     if not args.multiprocessing_distributed or (args.multiprocessing_distributed\n",
    "#             and args.rank % ngpus_per_node == 0):\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': args.arch,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    print(model.LT)\n",
    "    print('epoch time', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-stationery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-carolina",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-upgrade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.tensor([[ 1.6376, -0.2284,  0.0860],\n",
    "        [ 0.1055,  1.9402, -0.0046],\n",
    "        [-0.0257, -0.2146,  1.5572]], device='cuda:0', requires_grad=True).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(weight,  torch.inverse(weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.inverse(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.inverse(model.LT.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-month",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/Dataset/scl/patch_images/2021.01.15/LBC521-20210112(1)/LBC521-20210112(1)_1006.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(path)\n",
    "# img = np.resize(img, (256,256,3))\n",
    "# img = torch.tensor(img)/255.\n",
    "# img.shape\n",
    "img = torch.randn(2,256,256,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = nn.Parameter(torch.eye(3, dtype=torch.float), requires_grad=True)\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.matmul(img, weight)\n",
    "# res[0]\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-scope",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-tongue",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_retina",
   "language": "python",
   "name": "pytorch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
